{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhg0l9Vx/aSMwpBxU+LMWT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadanBaduwal/feature-engineering/blob/main/2_General_concept_of_data_science.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzGjfhvCRsGH"
      },
      "source": [
        "# Feature learning/feature engineering/preprocessing (input data bata information nikalinxa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuaG_yq2GTmx"
      },
      "source": [
        "**Features**\n",
        "\n",
        "**Why feature engineering?**\n",
        "\n",
        "Before starting feature engineering let me ask some questions.\n",
        "\n",
        "* How do you find good student and bad student\n",
        "Good student have good marks, good attendance....\n",
        "Bad student have bad marks , bad attendance....\n",
        "\n",
        "\n",
        "* How do we identify man , cow ...\n",
        "Man have 2 leg, man have no tail , ...\n",
        "Cow have 4 leg, come have tail ,...\n",
        "\n",
        "This are features. So how to identity this features in CV we find edge detection,....\n",
        "\n",
        "* How do we vulgarity sentence, good sentence..\n",
        "\n",
        "Vulgarity sentence have vulgarity words,..\n",
        "Good sentence have good words...\n",
        "\n",
        "\n",
        "Feature engineering is all about extract information from data that make sense for our task( regression task, classification task...).\n",
        "\n",
        "* First we need domain knowledge\n",
        "* Second we need to look on provided raw data.\n",
        "* Third Lots of mathematics operation are done to extract information from raw data.\n",
        "* key things of features are features have direction and magnitude.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-W0I9uY19dl"
      },
      "source": [
        "# Steps( Datascience or ai)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOk4bumU1_wg"
      },
      "source": [
        "## Step 1: Data\n",
        "\n",
        "1. Data annotation\n",
        "\n",
        "2. Data collection\n",
        "\n",
        "3. Importing data\n",
        "\n",
        "4. Data augumentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TAt1OON2UOs"
      },
      "source": [
        "## Step 2 : Exploration\n",
        "\n",
        "1. Data prepration\n",
        "\n",
        "2. Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gW_o9B721jx"
      },
      "source": [
        "## Step 3 : Feature Engineering\n",
        "\n",
        "1. Feature generation\n",
        "\n",
        "2. Dimensionality reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFTXpExu4QmE"
      },
      "source": [
        "## Step 4 : Modeling\n",
        "1. Model Selection\n",
        "2. Natural Language Processing\n",
        "3. Computer Vision\n",
        "4. Audio\n",
        "5. Recommendation System\n",
        "6. Timeseries\n",
        "7. Framework extensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ihcOqn64zn3"
      },
      "source": [
        "## Step 5: Validation\n",
        "\n",
        "1. Model Training Monitoring\n",
        "2. Interpretability\n",
        "3. Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1F9lUMK47dR"
      },
      "source": [
        "## Step 6: Optimization\n",
        "\n",
        "1. Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiQwKqPQt3jP"
      },
      "source": [
        "## Step 7: Production\n",
        "\n",
        "1. Model Serialization\n",
        "2. Scalability\n",
        "3. Bechmark\n",
        "4. API\n",
        "5. Dashboard\n",
        "6. Adversarial testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1LPJ3511Q-E"
      },
      "source": [
        "# References (Important link)\n",
        "\n",
        "https://amitness.com/toolbox/#workflow\n",
        "\n",
        "https://www.data-to-viz.com/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xIIwdxAMjjj"
      },
      "source": [
        "Why feature engineering? Significance of feature engineering?\n",
        "\n",
        "* Feature engineering (image preprocessing,NLP preprocessing...) yo sab feature nikalna ko lagi ho ok.\n",
        "* feature nikalna kina jaruri x ki hamilai ml or deep learning algorithm ma data ko characteristic kura matra pass garnu x  so. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku3aTClZeUF0"
      },
      "source": [
        "Why feature engineering ? what happen if there is no feature engineering?\n",
        "\n",
        "Answer:\n",
        "\n",
        "* If there is no feature engineering then there is overfitting.\n",
        "* If there is no feature engineering then there is low accuracy.\n",
        "* If there is no feature engineering then there is high training time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0W3W47HmFHZ"
      },
      "source": [
        "###1. Earth ma jati number system (feature, data,...) x tyati tarikale kam garna sakinxa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdPO239UmRjI"
      },
      "source": [
        "### 2. What is machine learning:   \n",
        "\n",
        "#### X\n",
        "   * X_training\n",
        "   * X_test\n",
        "   * X_validation\n",
        "#### Y\n",
        "   * y_training\n",
        "   * y_test\n",
        "   * y_validation\n",
        "\n",
        "Yati variable(column,feature..) bich ko karobar nai machine learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK4VGei2nMy9"
      },
      "source": [
        "### 3. Feature>column\n",
        "\n",
        "### * Single column(single feature, single variable)\n",
        "### * Multiple column(multiple feature, multiple variable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY1Aw9q2N4GJ"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sMrZ7wRN6VU"
      },
      "source": [
        "### 1. Introduction to feature and data engineering.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoZ6bL6fN8G0"
      },
      "source": [
        "### 2. Missing data imputation(value missing ta hunai vayana)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBM9zOuNOADs"
      },
      "source": [
        "### 3. Outlier analysis and handling(data normal distributation hunuparyo, center ko waripari data distrubute hunuparyo, outlier hunuvayana)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gb5iT0EOCeL"
      },
      "source": [
        "### 4. Feature transformation(value numerical nai hunuparyo, too large or too small hunuvayana, normal distributation ma hunuparyo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn1XbRhHOFll"
      },
      "source": [
        "### 5. Feature selection(correlation is most yaha ni , cv ma ni convolution or correlation is most)\n",
        "\n",
        "     5.1. Kunai features haru ak apas ma correlated xan vanya auta drop gardeni jo target sanga low correlated x kinako duta le autai sense derako hunxa ni ta so\n",
        "     5.2 target sanga highly correlated features matra lini aru liyata matlab nai hudaina"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYyVuD45OIcZ"
      },
      "source": [
        "### 6. Data sampling and reduction,discretization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eoVLttXOKde"
      },
      "source": [
        "### 7. Feature creation(featute combine garyara naya feature banuni yasari combine gareko naya feature target sanga highly correlated vaya ramro hunxa so)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt8Qr84JoJjU"
      },
      "source": [
        "### 8. Handling Imbalance data( target variable ma auta ko majority hunu vayana , yadi auda dherai vaya tyo matra training hunxa arko training nai hudaina )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y58jJnnDHr7p"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pAWvReDHsiA"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLKyLZXTICFP"
      },
      "source": [
        "## 1. Note : Feature engineering ma every steps haru like missing data handling,outlier....haruma kunai hard and fast rule xaina data anushar depend garxa so data engineerig akdam vast x."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtgAyBrVFs4G"
      },
      "source": [
        "## Steps for feature engineering ( Play first with univariate analysis then play with multivariate analysis- descriptative statistics analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsxoV2DZFLFL"
      },
      "source": [
        "## 1. Preprocess each features step by step (dont worry if we have many feature do it, it make easy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "996jtOjaFlQ_"
      },
      "source": [
        "## 2. Find correlation between each feature with target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMEPKf1qJjlo"
      },
      "source": [
        "## 3. If feature are correlated with each other then we can drop one of them but notice that the drop feature and target are low correlated, otherwise we can't drop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5hYSmxjKVvt"
      },
      "source": [
        "## 4. Visulatize each feature or visualize each feature with target. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Usd_wjYpOr-A"
      },
      "source": [
        "## Keys:\n",
        "One the basis of following three things we do all feature engineering.\n",
        "\n",
        "*  Single variable(one feature) or multivariable(many features at a time)\n",
        "*  Datatype(numerical,categorical,nominal,mixed,datetime)\n",
        "* Visualization and mathematical prespective"
      ]
    }
  ]
}